# 跑通代码！

**【图像预处理】**

```python
import torchvision.transforms as transforms

# 定义数据预处理步骤 【compose -> 组成】
transform = transforms.Compose([
    transforms.Resize((128, 128)),     # 将图像大小调整为 128x128 像素
    transforms.RandomCrop(100),        # 随机裁剪图像为 100x100 像素，可以传两个参数(n,m)
    transforms.RandomHorizontalFlip(), # 随机水平翻转图像
	# 显然存在 RandomVerticalFlip()
    transforms.ToTensor(),             # 将图像转换为张量 【Tensor -> 张量】
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 图像标准化
	# Normalize这个函数先会对图像进行归一化，把原先 [0,256) 的数值除以 256 然后再做一个变换 output=(input-mean)/std，对于以 RGB 三颜色揉成的图像要写 [1*3] 的 tuple (0.5,0.5,0.5)，如果你是灰度图像，那么只需要 (0.5,) 
	# 归一化后每个数字会满足属于区间 [0,1)，变换一下就满足在[-1,1] 中间分布了。
])
```

对于随机水平竖直反转操作的必要性：比如现在我要识别图中的小狗，在一张照片里面不一定狗是正着出现的，可以是任意角度倾斜，所以你需要对它进行随机翻转。


**【定义完预处理器之后要加载数据集】**

```python
trainset=dataset.MNIST('/MNIST.data/',download=True/false,train=True/False,transform)
# 用于训练网路参数的一部分数据
# MNIST 是手写数字的数据集，函数第一个参数表示文件位置；
# download 表示是不是把数据集里的图片下载下来
# 如果没有将数据集下载下来，第一个参数中指定的地址将没有意义。
# train=True/False 表示是不是用于训练
# 最后一个参数是指使用上面定义过的处理器处理所有图片

valset=dataset.MNIST('/MNIST.data/',download=True,train=False,transform)
# 用于测试 accuracy 的一部分数据    
dataiter = iter(trainloader)
images, labels = next(dataiter)
# dataiter 的取用需要 next() 函数，上面一行的赋值是把 image labels 都变成了 torch.Tensor
# 每次 next 会让 dataiter 挪到下一个
```

**【可视化图片】**

```python
import matplotlib.pyplot as plt

plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')
# squeeze 将冗余的维度压掉，比如 image[0].shape=(1,28,28)，压缩后是(28,28)
# cmap 是色彩映射，可能的参数有 plasma/viridis/inferno/magma/grey,grey_r/jet 大概就是不同表达方式。

figure = plt.figure() # 创建一个新的图片对象
num_of_images = 60
for index in range(1, num_of_images + 1):
    plt.subplot(6, 10, index) # 6，10 表示子图布局的行数列数 index 当前图片的位置
    plt.axis('off') # : 用于关闭当前子图的坐标轴刻度和标签，使子图上就不显示坐标轴，改成 on 一看笑死我了。
    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')

plt.show() # 感觉上是实例对象的语法，展示的可能是 figure
```



**【建立神经网络】**

```python
def create_model():
    input_size = 784 # 28*28=784 
    output_size = 10 # 类型 10 种
    model = nn.Sequential( # 【sequential->顺序的】 
        nn.Linear(input_size, 96),# input layer
        nn.ReLU(),# hidden layer，这层网络里面有96个节点
        nn.Linear(96, output_size), # output layer
        nn.LogSoftmax(dim=1) # 把 output layer 里面的所有数字变成加和为 1的数字
    )
    return model
```



softmax是指：$z_i=\dfrac{e^{v_i}}{\sum\limits e^{v_i}}$ ，这是用来归一化的（把变量按照大小映射到 $[0,1]$ 中）

但是他的一个问题就是 $z_i$ 在从 hidden layer 里面出来时大小不保证，$\exp$ 之后可能过于之大了。

优化方法是 Logsoftmax，求出概率的对数，$v_i-\log(\sum e^{v_i})$

网上说可以直接理解成 $v_i-\max v$ ，再 $\exp$ 就一定是 $[0,1]$ 里面的数字了。虽然疑惑很显然，但是相信库函数牛逼吧。

# 乱写

- 图像分割：在图片上随机 2000 个矩形跑图像识别（单个物体分类），据说是有很高的召回率。

# 待学习的事项

如何保存丹药